{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing...\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "print(\"Importing...\")\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import easyocr\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import recognizer_modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "##########               INPUTS               ##########\n",
    "########################################################\n",
    "\n",
    "VIDEO_PATH = r\"TestVideos\\Test_window.avi\"\n",
    "# VIDEO_PATH = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP = cv2.VideoCapture(VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurate image processing\n",
      "Configurating end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\WORKS\\Diplom-work\\recognizer_modules.py:150: UserWarning: Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\n",
      "  for variable in self.variable_windows:\n",
      "d:\\WORKS\\Diplom-work\\recognizer_modules.py:150: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\n",
      "  for variable in self.variable_windows:\n"
     ]
    }
   ],
   "source": [
    "## PreProcessor settings\n",
    "rules = dict(re_rule=r'-?\\d{1,3}\\.\\d', )\n",
    "variable_patterns = {'Viscosity': rules, 'Temperature': rules}\n",
    "\n",
    "\n",
    "class PreProcessor(recognizer_modules.PreProcessor):\n",
    "    Blur = range(1, 50)\n",
    "\n",
    "    def process(self, image):\n",
    "        image = cv2.blur(image, (int(self['Blur']), int(self['Blur'])))\n",
    "        try:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        except:\n",
    "            pass\n",
    "        image = cv2.bitwise_not(image)\n",
    "        return image\n",
    "    \n",
    "if VIDEO_PATH is None:\n",
    "    input_path = ''\n",
    "    while input_path == '':\n",
    "        input_path = input(f\"Input video path: \")\n",
    "    VIDEO_PATH = input_path\n",
    "\n",
    "CAP = cv2.VideoCapture(VIDEO_PATH)\n",
    "FPS = int(CAP.get(cv2.CAP_PROP_FPS))\n",
    "LENTH = int(CAP.get(cv2.CAP_PROP_FRAME_COUNT) / FPS)\n",
    "CAP.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, START_FRAME = CAP.read()\n",
    "\n",
    "processor = PreProcessor([i for i in variable_patterns])\n",
    "processor.configure_process(CAP)\n",
    "processor.select_window(CAP)\n",
    "processor.check_process(CAP)\n",
    "print('Configurating end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, START_FRAME = CAP.read()\n",
    "START_FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with video capterer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0, 0), (0, 0))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# CAP = cv2.VideoCapture(VIDEO_PATH)\n",
    "# CAP.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, START_FRAME = CAP.read()\n",
    "cap = CAP\n",
    "cv2.namedWindow('Frame')\n",
    "# if not cap.isOpened():\n",
    "#     raise NameError\n",
    "\n",
    "# Our ROI, defined by two points\n",
    "p1, p2 = (0, 0), (0, 0)\n",
    "drawing = False  # True while ROI is actively being drawn by mouse\n",
    "show_drawing = False  # True while ROI is drawn but is pending use or cancel\n",
    "blue_color = (255, 0, 0)\n",
    "\n",
    "\n",
    "def on_mouse(event, x, y, flags, userdata):\n",
    "    global p1, p2, drawing, show_drawing\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Left click down (select first point)\n",
    "        drawing = True\n",
    "        show_drawing = True\n",
    "        p1 = x, y\n",
    "        p2 = x, y\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        # Drag to second point\n",
    "        if drawing:\n",
    "            p2 = x, y\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        # Left click up (select second point)\n",
    "        drawing = False\n",
    "        p2 = x, y\n",
    "\n",
    "\n",
    "cv2.setMouseCallback('Frame', on_mouse)\n",
    "\n",
    "while True:\n",
    "    val, fr = cap.read()\n",
    "    if not val:\n",
    "        print('Error with video capterer')\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    if show_drawing:\n",
    "        p2 = (0 if p2[0] < 0 else\n",
    "              (p2[0] if p2[0] < fr.shape[1] else fr.shape[1]),\n",
    "              0 if p2[1] < 0 else\n",
    "              (p2[1] if p2[1] < fr.shape[0] else fr.shape[0]))\n",
    "        cv2.rectangle(fr, p1, p2, blue_color, 2)\n",
    "        # avg_y = (p1[1] + p2[1]) // 2\n",
    "        # cv2.line(fr, (p1[0], avg_y), (p2[0], avg_y), blue, 2)  # Middle horizontal line\n",
    "        # avg_x = (p1[0] + p2[0]) // 2\n",
    "        # cv2.line(fr, (avg_x, p1[1]), (avg_x, p2[1]), blue, 2)  # Middle vertical line\n",
    "\n",
    "    cv2.imshow('Frame', fr)\n",
    "\n",
    "    keyboard = cv2.waitKey(1)\n",
    "    if keyboard in [13, 32]:\n",
    "        # Pressed Enter or Space to use ROI\n",
    "        drawing = False\n",
    "        # show_drawing = False\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "    elif keyboard in [ord('c'), ord('C'), 27]:\n",
    "        CAP.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        # Pressed C or Esc to cancel ROI\n",
    "    elif keyboard in [ord('q'), ord('Q')]:\n",
    "        # Pressed Q to exit\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    # time.sleep(0.01)\n",
    "\n",
    "# cap.release()\n",
    "p1, p2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessor:\n",
    "    _parametr_configurations = []\n",
    "    parametrs = {}\n",
    "\n",
    "    def configure_process(\n",
    "        self,\n",
    "        video_capture,\n",
    "        start_frame: int = 0,\n",
    "        end_frame: int = 0,\n",
    "    ):\n",
    "\n",
    "        def update(val):\n",
    "            time = TIME_slider.val\n",
    "            video_capture.set(cv2.CAP_PROP_POS_FRAMES, int(fps * time))\n",
    "            _, image = video_capture.read()\n",
    "\n",
    "            for slider in sliders:\n",
    "                slider_name = str(slider.label).split(\"'\")[1]\n",
    "                self[slider_name] = slider.val\n",
    "\n",
    "            image_processed = self.process(image)\n",
    "            plot.set_data(image_processed)\n",
    "            plot.autoscale()\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(5, 5)\n",
    "        fig.subplots_adjust(\n",
    "            left=0.25,\n",
    "            right=1,\n",
    "            bottom=0.25,\n",
    "            top=1,\n",
    "            hspace=0,\n",
    "            wspace=0,\n",
    "        )\n",
    "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        _, image = video_capture.read()\n",
    "\n",
    "        plot = ax.imshow(self.process(image), cmap='binary')\n",
    "\n",
    "        time_slider_ax = fig.add_axes([0.25, 0.1, 0.65, 0.03])\n",
    "        fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "        max_len = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT) / fps) - 1\n",
    "        end_frame = max_len if not end_frame else end_frame\n",
    "\n",
    "        TIME_slider = Slider(\n",
    "            ax=time_slider_ax,\n",
    "            label='Time',\n",
    "            valmin=start_frame,\n",
    "            valmax=end_frame,\n",
    "            valinit=start_frame,\n",
    "            valstep=1,\n",
    "        )\n",
    "        TIME_slider.on_changed(update)\n",
    "\n",
    "        sliders = []\n",
    "        ofset = 0.2\n",
    "        for parametr, diap in self._parametr_configurations.items():\n",
    "            slider_ax = fig.add_axes([ofset, 0.25, 0.03, 0.6])\n",
    "\n",
    "            p_min = min(diap)\n",
    "            p_max = max(diap)\n",
    "            p_step = (max(diap) - min(diap)) / (len(diap) - 1)\n",
    "\n",
    "            slider = Slider(\n",
    "                ax=slider_ax,\n",
    "                orientation='vertical',\n",
    "                label=parametr,\n",
    "                valmin=p_min,\n",
    "                valmax=p_max,\n",
    "                valinit=self[parametr],\n",
    "                valstep=p_step,\n",
    "            )\n",
    "            slider.on_changed(update)\n",
    "            sliders.append(slider)\n",
    "            ofset -= 0.02\n",
    "\n",
    "        print('Configurate image processing')\n",
    "        plt.show()\n",
    "\n",
    "    def select_window(self, video_capture, i_frame=0):\n",
    "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
    "        _, image = video_capture.read()\n",
    "\n",
    "        for variable in self.variable_windows:\n",
    "            processed_image = self.process(image)\n",
    "            processed_image = cv2.bitwise_not(processed_image)\n",
    "            # TODO: make border color=red\n",
    "            window = cv2.selectROI(\n",
    "                f\"Select {variable}\",\n",
    "                processed_image,\n",
    "                fromCenter=False,\n",
    "                showCrosshair=True,\n",
    "            )\n",
    "            self.variable_windows[variable] = window\n",
    "        cv2.destroyAllWindows()\n",
    "    def select_window2(self, video_capture, i_frame=0):\n",
    "        \n",
    "        \n",
    "        ...\n",
    "    def check_process(\n",
    "        self,\n",
    "        video_capture,\n",
    "        start_frame: int = 0,\n",
    "        end_frame: int = 0,\n",
    "    ):\n",
    "\n",
    "        def update(val):\n",
    "            time = TIME_slider.val\n",
    "            video_capture.set(cv2.CAP_PROP_POS_FRAMES, int(fps * time))\n",
    "            _, image = video_capture.read()\n",
    "\n",
    "            image_processed = self.process(image)\n",
    "            stricted_images_list = self.strict(image_processed)\n",
    "\n",
    "            i = 0\n",
    "            for variable in self.variable_windows:\n",
    "                plots[i].set_data(stricted_images_list[variable])\n",
    "                plots[i].autoscale()\n",
    "                i += 1\n",
    "\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "        fig, axises = plt.subplots(nrows=len(self.variable_windows) + 1)\n",
    "        fig.set_size_inches(5, 5)\n",
    "        fig.subplots_adjust(\n",
    "            left=0.1,\n",
    "            right=0.9,\n",
    "            bottom=0.0,\n",
    "            top=1,\n",
    "            hspace=0.0,\n",
    "            wspace=0.1,\n",
    "        )\n",
    "        if not isinstance(axises, np.ndarray): axises = [axises]\n",
    "\n",
    "        time_slider_ax = axises[0]\n",
    "        axises = axises[1:]\n",
    "\n",
    "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        _, image = video_capture.read()\n",
    "        image_processed = self.process(image)\n",
    "        stricted_images_list = self.strict(image_processed)\n",
    "\n",
    "        plots = []\n",
    "        i = 0\n",
    "        for variable in self.variable_windows:\n",
    "            plots.append(\n",
    "                axises[i].imshow(\n",
    "                    stricted_images_list[variable],\n",
    "                    cmap='binary',\n",
    "                ), )\n",
    "            i += 1\n",
    "        fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "        max_len = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT) / fps) - 1\n",
    "        end_frame = max_len if not end_frame else end_frame\n",
    "\n",
    "        TIME_slider = Slider(\n",
    "            ax=time_slider_ax,\n",
    "            label='Time',\n",
    "            valmin=start_frame,\n",
    "            valmax=end_frame,\n",
    "            valinit=start_frame,\n",
    "            valstep=1,\n",
    "        )\n",
    "        TIME_slider.on_changed(update)\n",
    "        plt.show()\n",
    "\n",
    "    def strict(self, image: np.ndarray) -> np.ndarray:\n",
    "        images = {}\n",
    "        for variable, window in self.variable_windows.items():\n",
    "            x, y, dx, dy = window\n",
    "            images[variable] = image[y:y + dy, x:x + dx]\n",
    "        return images\n",
    "\n",
    "    def process(self, image: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __init__(self, variables):\n",
    "        all_fields = dict(self.__class__.__dict__)\n",
    "        self._parametr_configurations = {\n",
    "            key: value\n",
    "            for key, value in all_fields.items()\n",
    "            if key[0].isupper()\n",
    "        }\n",
    "        self.parametrs = {\n",
    "            key: min(value)\n",
    "            for key,\n",
    "            value in self._parametr_configurations.items()\n",
    "        }\n",
    "        self.variable_windows = {variable: 0 for variable in variables}\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.parametrs[item]\n",
    "\n",
    "    def __setitem__(self, item, value):\n",
    "        self.parametrs[item] = value\n",
    "\n",
    "    def __call__(self, image) -> np.ndarray:\n",
    "        return self.process(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PostProcessor settings\n",
    "class PostProcessor(recognizer_modules.PostProcessor):\n",
    "    def pattern(\n",
    "        self,\n",
    "        value: list,\n",
    "        re_rule=None, min_rule=None, max_rule=None,\n",
    "\n",
    "    ) -> float|None:\n",
    "\n",
    "        if value == []: return None\n",
    "        value = value[0]\n",
    "        value = value.replace(',', '.')\n",
    "        regexp_cond = len(re.findall(re_rule, value)) == 1\n",
    "        try:\n",
    "            value = float(value)\n",
    "        except ValueError:\n",
    "            return None\n",
    "        min_cond = value <= min_rule if min_rule is not None else True\n",
    "        max_cond = value >= max_rule if max_rule is not None else True\n",
    "\n",
    "        return value if regexp_cond and min_cond and max_cond else None\n",
    "    \n",
    "    @recognizer_modules.PostProcessor._check_type\n",
    "    def processor_sweep(self)->list[str]:\n",
    "        for i in range(1, 50):\n",
    "            self.inner_processor['Blur'] = i\n",
    "            processed_img = self.inner_processor(self._image)\n",
    "            raw_value = [\n",
    "                value for _, value, _ in self._reader.readtext(processed_img)\n",
    "            ]\n",
    "\n",
    "            result = self.pattern(raw_value,**self._rules)\n",
    "            if result is not None: return raw_value\n",
    "        return []\n",
    "\n",
    "    @recognizer_modules.PostProcessor._check_type\n",
    "    def value_combine(self) -> list[str]:\n",
    "        parts = len(self._raw_value)\n",
    "        if parts == 1:\n",
    "            value = self._raw_value[0]\n",
    "            result = value[:3] + '.' + value[4:5]\n",
    "\n",
    "        elif parts == 2:\n",
    "            result = '.'.join(self._raw_value)\n",
    "\n",
    "        elif parts == 3:\n",
    "            result = f'{self._raw_value[0]}.{self._raw_value[2]}'\n",
    "\n",
    "        return [result]\n",
    "    \n",
    "print('Starting recognizer...')\n",
    "reader = easyocr.Reader(['en'])\n",
    "checker=PostProcessor(reader=reader, processor=processor)\n",
    "print([i for i in checker.all_checks])\n",
    "# checker.active_checks_order = {check:checker.all_checks[check] for check in ['inner_processor_check','value_combine']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recognize\n",
    "input_fps = input('Input number of frames per second: ')\n",
    "try:\n",
    "    read_fps = float(input_fps)\n",
    "except:\n",
    "    read_fps = 1\n",
    "\n",
    "print('Recognizing:')\n",
    "errors = 0\n",
    "frame_line = tqdm(iterable=range(0, FPS * LENTH, int(FPS / read_fps)))\n",
    "frame_line.set_description(f'Errors: {errors: >4}')\n",
    "data = []\n",
    "\n",
    "for i_frame in frame_line:\n",
    "    CAP.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
    "    _, frame = CAP.read()\n",
    "    i_text = {'time': round(i_frame / FPS, 1)}\n",
    "    processed_frame = processor(frame)\n",
    "    stricted_images = processor.strict(processed_frame)\n",
    "\n",
    "    for var, rules in variable_patterns.items():\n",
    "        var_image = stricted_images[var]\n",
    "        raw_value = [\n",
    "            value for _, value, _ in reader.readtext(var_image)\n",
    "        ]\n",
    "\n",
    "        mark, result = checker.check(image=var_image,\n",
    "                               raw_value=raw_value,\n",
    "                               rules=rules)\n",
    "        i_text[var] = result\n",
    "        i_text[var + '_verbose'] = mark\n",
    "\n",
    "    if None in i_text.values():\n",
    "        errors += 1\n",
    "        frame_line.set_description(f'Errors: {errors: >4}')\n",
    "    data.append(i_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print\n",
    "print(pd.DataFrame(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('zVid_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4d32684a09710538003f28a4c8b9c69f5e1c5243c1252fb263c13f8fa834dd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
