{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "print(\"Importing...\")\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import easyocr\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from recognizer_modules import PreProcessor, PostProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inputs\n",
    "VIDEO_PATH = r\"Examples\\Test\\Test_window.avi\"\n",
    "# VIDEO_PATH = None\n",
    "rules = dict(re_rule=r'-?\\d{1,3}\\.\\d', )\n",
    "variable_patterns = {'Viscosity': rules, 'Temperature': rules}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PreProcessor settings\n",
    "class ImagePreProcessor(PreProcessor):\n",
    "    Blur = range(1, 50)\n",
    "\n",
    "    def process(self, image, gray_image=True):\n",
    "        image = cv2.blur(image, (int(self['Blur']), int(self['Blur'])))\n",
    "        if gray_image:\n",
    "            try:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            except:\n",
    "                pass\n",
    "            image = cv2.bitwise_not(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "if VIDEO_PATH is None:\n",
    "    input_path = ''\n",
    "    while input_path == '':\n",
    "        input_path = input(f\"Input video path: \")\n",
    "    VIDEO_PATH = input_path\n",
    "\n",
    "CAP = cv2.VideoCapture(VIDEO_PATH)\n",
    "FPS = int(CAP.get(cv2.CAP_PROP_FPS))\n",
    "LENTH = int(CAP.get(cv2.CAP_PROP_FRAME_COUNT) / FPS)\n",
    "CAP.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, START_FRAME = CAP.read()\n",
    "\n",
    "processor = ImagePreProcessor([i for i in variable_patterns])\n",
    "print('Configurate image processing')\n",
    "processor.configure_process(CAP)\n",
    "print(\n",
    "    'Press:',\n",
    "    '   Enter - save selection and continue',\n",
    "    '   R     - reset video timer',\n",
    "    '   Ecs/C - cancel selection',\n",
    "    sep='\\n',\n",
    ")\n",
    "processor.select_window(CAP)\n",
    "processor.check_process(CAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PostProcessor settings\n",
    "class ValuePostProcessor(PostProcessor):\n",
    "\n",
    "    def pattern(\n",
    "        self,\n",
    "        value: list,\n",
    "        re_rule=None,\n",
    "        min_rule=None,\n",
    "        max_rule=None,\n",
    "    ) -> float|None:\n",
    "\n",
    "        if value == []: return None\n",
    "        value = value[0]\n",
    "        value = value.replace(',', '.')\n",
    "        regexp_cond = len(re.findall(re_rule, value)) == 1\n",
    "        try:\n",
    "            value = float(value)\n",
    "        except ValueError:\n",
    "            return None\n",
    "        min_cond = value <= min_rule if min_rule is not None else True\n",
    "        max_cond = value >= max_rule if max_rule is not None else True\n",
    "\n",
    "        return value if regexp_cond and min_cond and max_cond else None\n",
    "\n",
    "    @PostProcessor._check_type\n",
    "    def processor_sweep(self) -> list[str]:\n",
    "        for i in range(1, 20):\n",
    "            self.inner_processor['Blur'] = i\n",
    "            processed_img = self.inner_processor(self._image)\n",
    "            raw_value = [\n",
    "                value for _, value, _ in self._reader.readtext(processed_img)\n",
    "            ]\n",
    "\n",
    "            result = self.pattern(raw_value, **self._rules)\n",
    "            if result is not None: return raw_value\n",
    "        return []\n",
    "\n",
    "    @PostProcessor._check_type\n",
    "    def value_combine(self) -> list[str]:\n",
    "        parts = len(self._raw_value)\n",
    "        if parts == 1:\n",
    "            value = self._raw_value[0]\n",
    "            result = value[:3] + '.' + value[4:5]\n",
    "\n",
    "        elif parts == 2:\n",
    "            result = '.'.join(self._raw_value)\n",
    "\n",
    "        elif parts == 3:\n",
    "            result = f'{self._raw_value[0]}.{self._raw_value[2]}'\n",
    "\n",
    "        return [result]\n",
    "\n",
    "\n",
    "print('Starting recognizer...')\n",
    "reader = easyocr.Reader(['en'])\n",
    "checker = ValuePostProcessor(reader=reader, processor=processor)\n",
    "print([i for i in checker.all_checks])\n",
    "# checker.active_checks_order = {check:checker.all_checks[check] for check in ['inner_processor_check','value_combine']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recognize\n",
    "input_fps = input('Input number of frames per second: ')\n",
    "try:\n",
    "    read_fps = float(input_fps)\n",
    "except:\n",
    "    read_fps = 1\n",
    "\n",
    "print('Recognizing:')\n",
    "errors = 0\n",
    "frame_line = tqdm(iterable=range(0, FPS * LENTH, int(FPS / read_fps)))\n",
    "frame_line.set_description(f'Errors: {errors: >4}')\n",
    "data = []\n",
    "\n",
    "for i_frame in frame_line:\n",
    "    CAP.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
    "    _, frame = CAP.read()\n",
    "    i_text = {'time': round(i_frame / FPS, 1)}\n",
    "    processed_frame = processor(frame)\n",
    "    stricted_images = processor.strict(processed_frame)\n",
    "\n",
    "    for var, rules in variable_patterns.items():\n",
    "        var_image = stricted_images[var]\n",
    "        raw_value = [value for _, value, _ in reader.readtext(var_image)]\n",
    "\n",
    "        mark, result = checker.check(image=var_image,\n",
    "                               raw_value=raw_value,\n",
    "                               rules=rules)\n",
    "        if mark == 'error':\n",
    "            processor.configure_process(CAP,start_frame=i_frame)\n",
    "            processor.select_window(CAP,start_frame=i_frame)\n",
    "            processor.check_process(CAP,start_frame=i_frame)\n",
    "            checker.reload_processor(processor)\n",
    "            mark, result = checker.check(image=var_image,\n",
    "                        raw_value=raw_value,\n",
    "                        rules=rules)\n",
    "            mark= f'*{mark}'\n",
    "        i_text[var] = result\n",
    "        i_text[var + '_verbose'] = mark\n",
    "\n",
    "    if None in i_text.values():\n",
    "        errors += 1\n",
    "        frame_line.set_description(f'Errors: {errors: >4}')\n",
    "    data.append(i_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print\n",
    "print(pd.DataFrame(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('zVid_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4d32684a09710538003f28a4c8b9c69f5e1c5243c1252fb263c13f8fa834dd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
