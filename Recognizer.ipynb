{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing...\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "print(\"Importing...\")\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import easyocr\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.widgets import Slider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "##########               INPUTS               ##########\n",
    "########################################################\n",
    "\n",
    "VIDEO_PATH = \"Videos/Exp0/Exp0_1.avi\"\n",
    "# VIDEO_PATH = None\n",
    "rules = dict(re_rule=r'-?\\d{1,3}\\.\\d', )\n",
    "RECOGNIZABLE_VARIABLES = [\n",
    "    dict(name='Viscosity', rules=rules),\n",
    "    dict(name='Temperature', rules=rules),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global settings\n",
    "if VIDEO_PATH is None:\n",
    "    input_path = ''\n",
    "    while input_path == '':\n",
    "        input_path = input(f\"Input video path: \")\n",
    "    VIDEO_PATH = input_path\n",
    "\n",
    "CAP = cv2.VideoCapture(VIDEO_PATH)\n",
    "FPS = int(CAP.get(cv2.CAP_PROP_FPS))\n",
    "LENTH = int(CAP.get(cv2.CAP_PROP_FRAME_COUNT) / FPS)\n",
    "CAP.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, START_FRAME = CAP.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15, 15)\n",
    "fig.subplots_adjust(left=0.25, right=1, bottom=0.25, top=1, hspace=0, wspace=0)\n",
    "ax_time_slider = fig.add_axes([0.25, 0.1, 0.65, 0.03])\n",
    "a= Slider(\n",
    "            ax=ax_time_slider,\n",
    "            label='blur',\n",
    "            valmin=0,\n",
    "            valmax=20,\n",
    "            valinit=0,\n",
    "            valstep=1,\n",
    "        )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image processor\n",
    "class ImageProcessor:\n",
    "    variables = []\n",
    "    _parametr_configurations = []\n",
    "    _parametrs = {}\n",
    "\n",
    "    def configure_preprocess(self, video_capture):\n",
    "\n",
    "        def update():\n",
    "            time = TIME_slider.val\n",
    "            video_capture.set(cv2.CAP_PROP_POS_FRAMES, int(FPS * time))\n",
    "            _, frame = video_capture.read()\n",
    "\n",
    "            for slider in sliders:\n",
    "                slider_name = str(slider.label).split(\"'\")[1]\n",
    "                self[slider_name] = slider.val\n",
    "\n",
    "            frame = self.process(frame)\n",
    "            plot.set_data(frame)\n",
    "            plot.autoscale()\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(15, 15)\n",
    "        fig.subplots_adjust(\n",
    "            left=0.25,\n",
    "            right=1,\n",
    "            bottom=0.25,\n",
    "            top=1,\n",
    "            hspace=0,\n",
    "            wspace=0,\n",
    "        )\n",
    "\n",
    "        plot = ax.imshow(self.process(START_FRAME), cmap='binary')\n",
    "\n",
    "        time_slider_ax = fig.add_axes([0.25, 0.1, 0.65, 0.03])\n",
    "        TIME_slider = Slider(\n",
    "            ax=time_slider_ax,\n",
    "            label='Time',\n",
    "            valmin=0,\n",
    "            valmax=self.video_len - 1,\n",
    "            valinit=0,\n",
    "            valstep=1,\n",
    "        )\n",
    "\n",
    "        sliders = []\n",
    "        ofset = 0.2\n",
    "        for parametr, diap in self._parametr_configurations.items():\n",
    "            slider_ax = fig.add_axes([ofset, 0.25, 0.03, 0.6])\n",
    "\n",
    "            p_min = min(diap)\n",
    "            p_max = max(diap)\n",
    "            p_step = (max(diap) - min(diap)) / (len(diap) - 1)\n",
    "\n",
    "            slider = Slider(\n",
    "                ax=slider_ax,\n",
    "                orientation='vertical',\n",
    "                label='Blur',\n",
    "                valmin=p_min,\n",
    "                valmax=p_max,\n",
    "                valinit=p_min,\n",
    "                valstep=p_step,\n",
    "            )\n",
    "            slider.on_changed(update)\n",
    "            sliders.append(slider)\n",
    "            ofset -= 0.02\n",
    "\n",
    "        print('Configurate image processing')\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def strict(image, x, y, w, h):\n",
    "        return image[y:y + h, x:x + w]\n",
    "\n",
    "    def select_window(self):\n",
    "        ...\n",
    "\n",
    "    def process(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __init__(self):\n",
    "        all_fields = dict(self.__dict__)\n",
    "        self._parametr_configurations = {\n",
    "            key: value\n",
    "            for key, value in all_fields.items()\n",
    "            if key[0].isupper()\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self._parametrs[item]\n",
    "\n",
    "    def __setitem__(self, item, value):\n",
    "        self._parametrs[item] = value\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.process(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(ImageProcessor):\n",
    "    Blur = range(1, 50)\n",
    "    \n",
    "    variables = [\n",
    "    dict(name='Viscosity', rules=rules),\n",
    "    dict(name='Temperature', rules=rules),\n",
    "]\n",
    "    def process(self, image):\n",
    "        image = cv2.blur(image, (self['blur'], self['blur']))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.bitwise_not(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup processor confings\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5, 5)\n",
    "fig.subplots_adjust(left=0.25, right=1, bottom=0.25, top=1, hspace=0, wspace=0)\n",
    "\n",
    "image_processor = lambda x:x\n",
    "PLOT = ax.imshow(image_processor(START_FRAME), cmap='binary')\n",
    "\n",
    "ax_time_slider = fig.add_axes([0.25, 0.1, 0.65, 0.03])\n",
    "TIME_slider = Slider(\n",
    "    ax=ax_time_slider,\n",
    "    label='Time',\n",
    "    valmin=0,\n",
    "    valmax=LENTH,\n",
    "    valinit=0,\n",
    "    valstep=1,\n",
    ")\n",
    "\n",
    "ax_blur_slider = fig.add_axes([0.1, 0.25, 0.03, 0.6])\n",
    "BLUR_slider = Slider(\n",
    "    ax=ax_blur_slider,\n",
    "    orientation='vertical',\n",
    "    label='Blur',\n",
    "    valmin=1,\n",
    "    valmax=50,\n",
    "    valinit=1,\n",
    "    valstep=1,\n",
    ")\n",
    "\n",
    "\n",
    "def update(val):\n",
    "    time = TIME_slider.val\n",
    "    global image_processor\n",
    "    print(BLUR_slider.val)\n",
    "\n",
    "    CAP.set(cv2.CAP_PROP_POS_FRAMES, int(FPS * time))\n",
    "    _, frame = CAP.read()\n",
    "    frame = image_processor(frame)\n",
    "\n",
    "    PLOT.set_data(frame)\n",
    "    PLOT.autoscale()\n",
    "\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "TIME_slider.on_changed(update)\n",
    "BLUR_slider.on_changed(update)\n",
    "print('Configurate image processing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(6, 3)\n",
    "    fig.subplots_adjust(left=0.2, right=0.95, bottom=0.05, top=1, hspace=0, wspace=0)\n",
    "\n",
    "    image_processor = lambda x:x\n",
    "    PLOT = ax.imshow(image_processor(START_FRAME), cmap='binary')\n",
    "\n",
    "    ax_time_slider = fig.add_axes([0.2, 0.05, 0.7, 0.05])\n",
    "    TIME_slider = Slider(\n",
    "        ax=ax_time_slider,\n",
    "        label='Time',\n",
    "        valmin=0,\n",
    "        valmax=LENTH,\n",
    "        valinit=0,\n",
    "        valstep=1,\n",
    "    )\n",
    "\n",
    "    ax_blur_slider = fig.add_axes([0.15, 0.25, 0.02, 0.6])\n",
    "    BLUR_slider = Slider(\n",
    "        ax=ax_blur_slider,\n",
    "        orientation='vertical',\n",
    "        label='Blur',\n",
    "        valmin=1,\n",
    "        valmax=50,\n",
    "        valinit=1,\n",
    "        valstep=1,\n",
    "    )\n",
    "\n",
    "\n",
    "    def update(val):\n",
    "        time = TIME_slider.val\n",
    "        print(BLUR_slider.val)\n",
    "\n",
    "        CAP.set(cv2.CAP_PROP_POS_FRAMES, int(FPS * time))\n",
    "        _, frame = CAP.read()\n",
    "        frame = image_processor(frame)\n",
    "\n",
    "        PLOT.set_data(frame)\n",
    "        PLOT.autoscale()\n",
    "\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "    TIME_slider.on_changed(update)\n",
    "    BLUR_slider.on_changed(update)\n",
    "    print('Configurate image processing')\n",
    "    plt.show()\n",
    "    return ax\n",
    "\n",
    "def foo2():\n",
    "    foo()\n",
    "    print('ffffff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurate image processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n",
      "13\n",
      "18\n",
      "20\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(6, 3)\n",
    "fig.subplots_adjust(left=0.2, right=0.95, bottom=0.05, top=1, hspace=0, wspace=0)\n",
    "\n",
    "image_processor = lambda x:x\n",
    "PLOT = ax.imshow(image_processor(START_FRAME), cmap='binary')\n",
    "\n",
    "ax_time_slider = fig.add_axes([0.2, 0.05, 0.7, 0.05])\n",
    "TIME_slider = Slider(\n",
    "    ax=ax_time_slider,\n",
    "    label='Time',\n",
    "    valmin=0,\n",
    "    valmax=LENTH,\n",
    "    valinit=0,\n",
    "    valstep=1,\n",
    ")\n",
    "\n",
    "ax_blur_slider = fig.add_axes([0.15, 0.25, 0.02, 0.6])\n",
    "BLUR_slider = Slider(\n",
    "    ax=ax_blur_slider,\n",
    "    orientation='vertical',\n",
    "    label='Blur',\n",
    "    valmin=1,\n",
    "    valmax=50,\n",
    "    valinit=1,\n",
    "    valstep=1,\n",
    ")\n",
    "\n",
    "\n",
    "def update(val):\n",
    "    time = TIME_slider.val\n",
    "    print(BLUR_slider.val)\n",
    "\n",
    "    CAP.set(cv2.CAP_PROP_POS_FRAMES, int(FPS * time))\n",
    "    _, frame = CAP.read()\n",
    "    frame = image_processor(frame)\n",
    "\n",
    "    PLOT.set_data(frame)\n",
    "    PLOT.autoscale()\n",
    "\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "TIME_slider.on_changed(update)\n",
    "BLUR_slider.on_changed(update)\n",
    "print('Configurate image processing')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurate image processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "13\n",
      "15\n",
      "17\n",
      "18\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "h= foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The Axes must have been created in the present figure",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m y \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n\u001b[1;32m----> 2\u001b[0m y\u001b[39m.\u001b[39;49madd_axes(h)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32md:\\WORKS\\Diplom-work\\zVid_env\\lib\\site-packages\\matplotlib\\figure.py:639\u001b[0m, in \u001b[0;36mFigureBase.add_axes\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    637\u001b[0m     key \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39m_projection_init\n\u001b[0;32m    638\u001b[0m     \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mget_figure() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 639\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    640\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe Axes must have been created in the present figure\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    641\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    642\u001b[0m     rect, \u001b[39m*\u001b[39mextra_args \u001b[39m=\u001b[39m args\n",
      "\u001b[1;31mValueError\u001b[0m: The Axes must have been created in the present figure"
     ]
    }
   ],
   "source": [
    "y = plt.figure()\n",
    "y.add_axes(h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= plt.plot([1,2,3,4,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.\n",
    "plt.plot([1,23,4,56,4,5,6,77,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selection\n",
    "def strict(image, x, y, w, h):\n",
    "    return image[y:y + h, x:x + w]\n",
    "\n",
    "\n",
    "print(f'Blur value= {image_processor.blur}')\n",
    "for variable in RECOGNIZABLE_VARIABLES:\n",
    "    roi_frame = image_processor(START_FRAME)\n",
    "    roi_frame = cv2.bitwise_not(roi_frame)\n",
    "    current_slice = cv2.selectROI(\n",
    "        f\"Select {variable['name']}\",\n",
    "        roi_frame,\n",
    "        fromCenter=False,\n",
    "        showCrosshair=True,\n",
    "    )\n",
    "    variable['slice'] = current_slice\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Result plots\n",
    "fig, axes = plt.subplots(nrows=len(RECOGNIZABLE_VARIABLES))\n",
    "# fig.set_t\n",
    "if not isinstance(axes, np.ndarray): axes = [axes]\n",
    "fig.set_size_inches(3, 1 * len(RECOGNIZABLE_VARIABLES))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0.0, top=1, hspace=0, wspace=0)\n",
    "start_slices = [\n",
    "    strict(image_processor(START_FRAME), *variable['slice'])\n",
    "    for variable in RECOGNIZABLE_VARIABLES\n",
    "]\n",
    "for i in range(len(RECOGNIZABLE_VARIABLES)):\n",
    "    axes[i].set_axis_off()\n",
    "    axes[i].imshow(start_slices[i], cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueChecker:\n",
    "\n",
    "    def check(self, image, raw_value, rules):\n",
    "        pattern_check = self._pattern_check(raw_value, **rules)\n",
    "        if pattern_check is not None: return 0, pattern_check\n",
    "\n",
    "        img_check = self._image_check(image, rules)\n",
    "        if img_check is not None: return 1, img_check\n",
    "\n",
    "        # value_check = self._value_check(raw_value)\n",
    "        # if value_check is not None: return 2,value_check\n",
    "        return 3, None\n",
    "\n",
    "    def __init__(self, processor: ImageProcessor, reader):\n",
    "        self._processor = copy.deepcopy(processor)\n",
    "        self._reader = reader\n",
    "\n",
    "    def _pattern_check(\n",
    "        self,\n",
    "        value: list,\n",
    "        re_rule=None,\n",
    "        min_rule=None,\n",
    "        max_rule=None,\n",
    "    ):  \n",
    "        if value==[]: return None\n",
    "        value = value[0]\n",
    "        value = value.replace(',', '.')\n",
    "        one_check = len(re.findall(re_rule, value)) == 1\n",
    "        try:\n",
    "            value = float(value)\n",
    "        except ValueError:\n",
    "            return None\n",
    "        min_check = value <= min_rule if min_rule is not None else True\n",
    "        max_check = value >= max_rule if max_rule is not None else True\n",
    "\n",
    "        result = value if one_check and min_check and max_check else None\n",
    "        return result\n",
    "    def processor_configurator(self):\n",
    "        for i in range(1,50):\n",
    "            self._processor.blur=i\n",
    "            yield True\n",
    "        \n",
    "    def _image_check(self, image, rules):\n",
    "        configurator = self.processor_configurator()\n",
    "        loop=True\n",
    "        while loop:\n",
    "            processed_img = self._processor(image=image)\n",
    "            raw_value = [\n",
    "                value for _, value, _ in self._reader.readtext(processed_img)\n",
    "            ]\n",
    "            \n",
    "            result = self._pattern_check(raw_value, **rules)\n",
    "            if result is not None:\n",
    "                return result\n",
    "            else:\n",
    "                try:\n",
    "                    loop = configurator.__next__()\n",
    "                except StopIteration:\n",
    "                    return None\n",
    "                \n",
    "\n",
    "    def _value_check(self, raw_value: list):\n",
    "        parts = len(raw_value)\n",
    "        if parts == 1:\n",
    "            try:\n",
    "                check_result = float(raw_value[0])\n",
    "                if check_result > 1000:\n",
    "                    raw_result = str(check_result)\n",
    "                    raw_result = raw_result[:3] + '.' + raw_result[4]\n",
    "            except:\n",
    "                raw_result = None\n",
    "\n",
    "        elif parts == 2:\n",
    "            raw_result = '.'.join(raw_value)\n",
    "\n",
    "        elif parts == 3:\n",
    "            raw_result = f'{raw_value[0]}.{raw_value[2]}'\n",
    "\n",
    "        try:\n",
    "            result = float(raw_result)\n",
    "        except:\n",
    "            result = None\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recognize\n",
    "print('Starting recognizer...')\n",
    "reader = easyocr.Reader(['en'])\n",
    "checker = ValueChecker(reader=reader, processor=image_processor)\n",
    "\n",
    "input_fps = input('Input number of frames per second: ')\n",
    "try:\n",
    "    read_fps = float(input_fps)\n",
    "except:\n",
    "    read_fps = 1\n",
    "\n",
    "print('Recognizing:')\n",
    "errors = 0\n",
    "frame_line = tqdm(iterable=range(0, FPS * LENTH, int(FPS / read_fps)))\n",
    "frame_line.set_description(f'Errors: {errors: >4}')\n",
    "data = []\n",
    "for i_frame in frame_line:\n",
    "    CAP.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
    "    _, frame = CAP.read()\n",
    "    i_text = {'time': round(i_frame / FPS, 1)}\n",
    "    for variable in RECOGNIZABLE_VARIABLES:\n",
    "        selection = strict(frame, *variable['slice'])\n",
    "        processed_img = image_processor(selection)\n",
    "        raw_value = [value for _, value, _ in reader.readtext(processed_img)]\n",
    "        \n",
    "        mark, result = checker.check(image=selection,\n",
    "                               raw_value=raw_value,\n",
    "                               rules=variable['rules'])\n",
    "        i_text[variable['name']] = result\n",
    "        i_text[variable['name']+'_mark'] = mark\n",
    "\n",
    "    if None in i_text.values():\n",
    "        errors += 1\n",
    "        frame_line.set_description(f'Errors: {errors: >4}')\n",
    "    data.append(i_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print\n",
    "print(pd.DataFrame(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('zVid_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5946b119aa0342abd5386a0c5beb8d13f5e9da65c541c34995194e58e5a123e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
