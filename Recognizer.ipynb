{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %matplotlib qt\n",
        "# %matplotlib ipympl"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Imports\n",
        "print(\"Importing...\")\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "import easyocr\n",
        "\n",
        "from recognizer_modules import PreProcessor, PostProcessor, PathContainer"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Inputs\n",
        "PATHS = PathContainer()\n",
        "PATHS.print_paths()\n",
        "VARIABLE_PATTERNS = {\n",
        "    'Viscosity': r'-?\\d{1,3}[\\.,]\\d',\n",
        "    'Temperature': r'-?\\d{1,3}[\\.,]\\d',\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## PreProcessor settings\n",
        "class ImageProcessor(PreProcessor):\n",
        "    Blur = range(1, 50)\n",
        "\n",
        "    def process(self, image, gray_image=True):\n",
        "        image = cv2.blur(image, (int(self['Blur']), int(self['Blur'])))\n",
        "        if gray_image:\n",
        "            try:\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            except:\n",
        "                pass\n",
        "            image = cv2.bitwise_not(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "CAP = cv2.VideoCapture(PATHS.video_path)\n",
        "\n",
        "FPS = int(CAP.get(cv2.CAP_PROP_FPS))\n",
        "LENTH = int(CAP.get(cv2.CAP_PROP_FRAME_COUNT) / FPS)\n",
        "CAP.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "_, START_FRAME = CAP.read()\n",
        "\n",
        "processor = ImageProcessor([i for i in VARIABLE_PATTERNS])\n",
        "print('Configurate image processing')\n",
        "\n",
        "print(\n",
        "    'Press:',\n",
        "    '   Enter - save selection and continue',\n",
        "    '   R     - reset video timer',\n",
        "    '   Ecs/C - cancel selection',\n",
        "    '   q/e   - time move',\n",
        "    sep='\\n',\n",
        ")\n",
        "configure = True\n",
        "while configure:\n",
        "    processor.configure_process(CAP)\n",
        "    processor.select_window(CAP)\n",
        "    processor.check_process(CAP)\n",
        "    configure = False if input ('Continue (y for yes)? ')=='y' else True\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## PostProcessor settings\n",
        "class ValuePostProcessor(PostProcessor):\n",
        "\n",
        "    def convert(self, value: str):\n",
        "        value = value.replace(',', '.')\n",
        "        try:\n",
        "            result = float(value)\n",
        "            return result\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    @PostProcessor.check_type\n",
        "    def image_sweep_check(self) -> list[str]:\n",
        "        for i in range(1, 50):\n",
        "            self.inner_processor['Blur'] = i\n",
        "            processed_img = self.inner_processor(self.image)\n",
        "            raw_value = [\n",
        "                value for _, value, _ in self.reader.readtext(processed_img)\n",
        "            ]\n",
        "            result = self.isOK(raw_value)\n",
        "            if result is not None: return result\n",
        "\n",
        "    @PostProcessor.check_type\n",
        "    def combine_check(self) -> list[str]:\n",
        "        n_parts = len(self.input_value)\n",
        "        combined_value =[]\n",
        "        if n_parts == 1:\n",
        "            value = self.input_value[0]\n",
        "            combined_value = value[:3] + '.' + value[4:5]\n",
        "\n",
        "        elif n_parts == 2:\n",
        "            combined_value = '.'.join(self.input_value)\n",
        "\n",
        "        elif n_parts == 3:\n",
        "            combined_value = f'{self.input_value[0]}.{self.input_value[2]}'\n",
        "\n",
        "        return self.isOK(combined_value)\n",
        "\n",
        "input_fps = input('Input number of frames per second: ')\n",
        "try:\n",
        "    read_fps = float(input_fps)\n",
        "except:\n",
        "    read_fps = 1\n",
        "\n",
        "print('Starting recognizer...')\n",
        "reader = easyocr.Reader(['en'])\n",
        "checker = ValuePostProcessor(reader=reader, processor=processor)\n",
        "# checker.active_checks_order =\n",
        "# {check:checker.all_checks[check]\n",
        "# for check in ['inner_processor_check','value_combine']}\n",
        "print('Active checks:\\n', [i for i in checker.active_checks_order])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Recognize\n",
        "print('Recognizing:')\n",
        "errors = 0\n",
        "frame_line = tqdm(iterable=range(0, FPS * LENTH, int(FPS / read_fps)))\n",
        "frame_line.set_description(f'Errors: {errors: >4}')\n",
        "DATA = []\n",
        "\n",
        "for i_frame in frame_line:\n",
        "    CAP.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
        "    _, frame = CAP.read()\n",
        "    i_text = {'time': round(i_frame / FPS, 1)}\n",
        "    processed_frame = processor(frame)\n",
        "    stricted_images = processor.strict(processed_frame)\n",
        "\n",
        "    for var, pattern in VARIABLE_PATTERNS.items():\n",
        "        var_image = stricted_images[var]\n",
        "        raw_value = [value for _, value, _ in reader.readtext(var_image)]\n",
        "\n",
        "        verbose, result = checker.check(\n",
        "            input_value=raw_value,\n",
        "            pattern=pattern,\n",
        "            image = var_image,\n",
        "            )\n",
        "\n",
        "        # if mark == 'error':\n",
        "        #     # processor.configure_process(CAP,start_frame=i_frame)\n",
        "        #     processor.select_window(CAP,start_frame=i_frame)\n",
        "        #     # processor.check_process(CAP,start_frame=i_frame)\n",
        "        #     checker.reload_processor(processor)\n",
        "        #     mark, result = checker.check(image=var_image,\n",
        "        #                 raw_value=raw_value,\n",
        "        #                 rules=rules)\n",
        "        #     mark= f'*{mark}'\n",
        "\n",
        "        i_text[var] = result\n",
        "        i_text[var + '_verbose'] = verbose\n",
        "\n",
        "    if None in i_text.values():\n",
        "        errors += 1\n",
        "        frame_line.set_description(f'{errors: >4} errors')\n",
        "    DATA.append(i_text)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Saving\n",
        "df = pd.DataFrame(DATA)\n",
        "df.dropna().to_csv(PATHS.data_path,index=0)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}