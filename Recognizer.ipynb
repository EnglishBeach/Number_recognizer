{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "print(\"Importing...\")\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import easyocr\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.widgets import Slider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "##########               INPUTS               ##########\n",
    "########################################################\n",
    "\n",
    "VIDEO_PATH = \"Videos/Exp1/Exp1_1.mp4\"\n",
    "# VIDEO_PATH = None\n",
    "rules = dict(re_rule=r'-?\\d{1,3}\\.\\d', )\n",
    "RECOGNIZABLE_VARIABLES = [\n",
    "    dict(name='Viscosity', rules=rules),\n",
    "    dict(name='Temperature', rules=rules),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global settings\n",
    "if VIDEO_PATH is None:\n",
    "    input_path = ''\n",
    "    while input_path == '':\n",
    "        input_path = input(f\"Input video path: \")\n",
    "    VIDEO_PATH = input_path\n",
    "\n",
    "CAP = cv2.VideoCapture(VIDEO_PATH)\n",
    "FPS = int(CAP.get(cv2.CAP_PROP_FPS))\n",
    "LENTH = int(CAP.get(cv2.CAP_PROP_FRAME_COUNT) / FPS)\n",
    "CAP.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "_, START_FRAME = CAP.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image processor\n",
    "class ImageProcessor:\n",
    "    blur=1\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = cv2.blur(image, (self.blur, self.blur))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.bitwise_not(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup processor confings\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5, 5)\n",
    "fig.subplots_adjust(left=0.25, right=1, bottom=0.25, top=1, hspace=0, wspace=0)\n",
    "\n",
    "image_processor = ImageProcessor()\n",
    "PLOT = ax.imshow(image_processor(START_FRAME), cmap='binary')\n",
    "\n",
    "ax_time_slider = fig.add_axes([0.25, 0.1, 0.65, 0.03])\n",
    "TIME_slider = Slider(\n",
    "    ax=ax_time_slider,\n",
    "    label='Time',\n",
    "    valmin=0,\n",
    "    valmax=LENTH,\n",
    "    valinit=0,\n",
    "    valstep=1,\n",
    ")\n",
    "\n",
    "ax_blur_slider = fig.add_axes([0.1, 0.25, 0.03, 0.6])\n",
    "BLUR_slider = Slider(\n",
    "    ax=ax_blur_slider,\n",
    "    orientation='vertical',\n",
    "    label='Blur',\n",
    "    valmin=image_processor.blur,\n",
    "    valmax=50,\n",
    "    valinit=1,\n",
    "    valstep=1,\n",
    ")\n",
    "\n",
    "\n",
    "def update(val):\n",
    "    time = TIME_slider.val\n",
    "    global image_processor\n",
    "    image_processor.blur = BLUR_slider.val\n",
    "\n",
    "    CAP.set(cv2.CAP_PROP_POS_FRAMES, int(FPS * time))\n",
    "    _, frame = CAP.read()\n",
    "    frame = image_processor(frame)\n",
    "\n",
    "    PLOT.set_data(frame)\n",
    "    PLOT.autoscale()\n",
    "\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "TIME_slider.on_changed(update)\n",
    "BLUR_slider.on_changed(update)\n",
    "print('Configurate image processing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selection\n",
    "def strict(image, x, y, w, h):\n",
    "    return image[y:y + h, x:x + w]\n",
    "\n",
    "\n",
    "print(f'Blur value= {image_processor.blur}')\n",
    "for variable in RECOGNIZABLE_VARIABLES:\n",
    "    roi_frame = image_processor(START_FRAME)\n",
    "    roi_frame = cv2.bitwise_not(roi_frame)\n",
    "    current_slice = cv2.selectROI(\n",
    "        f\"Select {variable['name']}\",\n",
    "        roi_frame,\n",
    "        fromCenter=False,\n",
    "        showCrosshair=True,\n",
    "    )\n",
    "    variable['slice'] = current_slice\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Result plots\n",
    "fig, axes = plt.subplots(nrows=len(RECOGNIZABLE_VARIABLES))\n",
    "# fig.set_t\n",
    "if not isinstance(axes, np.ndarray): axes = [axes]\n",
    "fig.set_size_inches(3, 1 * len(RECOGNIZABLE_VARIABLES))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0.0, top=1, hspace=0, wspace=0)\n",
    "start_slices = [\n",
    "    strict(image_processor(START_FRAME), *variable['slice'])\n",
    "    for variable in RECOGNIZABLE_VARIABLES\n",
    "]\n",
    "for i in range(len(RECOGNIZABLE_VARIABLES)):\n",
    "    axes[i].set_axis_off()\n",
    "    axes[i].imshow(start_slices[i], cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueChecker:\n",
    "\n",
    "    def check(self, image, raw_value, rules):\n",
    "        pattern_check = self._pattern_check(raw_value, **rules)\n",
    "        if pattern_check is not None: return 0, pattern_check\n",
    "\n",
    "        img_check = self._image_check(image, rules)\n",
    "        if img_check is not None: return 1, img_check\n",
    "\n",
    "        # value_check = self._value_check(raw_value)\n",
    "        # if value_check is not None: return 2,value_check\n",
    "        return 3, None\n",
    "\n",
    "    def __init__(self, processor: ImageProcessor, reader):\n",
    "        self._processor = copy.deepcopy(processor)\n",
    "        self._reader = reader\n",
    "\n",
    "    def _pattern_check(\n",
    "        self,\n",
    "        value: list,\n",
    "        re_rule=None,\n",
    "        min_rule=None,\n",
    "        max_rule=None,\n",
    "    ):  \n",
    "        if value==[]: return None\n",
    "        value = value[0]\n",
    "        value = value.replace(',', '.')\n",
    "        one_check = len(re.findall(re_rule, value)) == 1\n",
    "        try:\n",
    "            value = float(value)\n",
    "        except ValueError:\n",
    "            return None\n",
    "        min_check = value <= min_rule if min_rule is not None else True\n",
    "        max_check = value >= max_rule if max_rule is not None else True\n",
    "\n",
    "        result = value if one_check and min_check and max_check else None\n",
    "        return result\n",
    "    def processor_configurator(self):\n",
    "        for i in range(1,50):\n",
    "            self._processor.blur=i\n",
    "            yield True\n",
    "        \n",
    "    def _image_check(self, image, rules):\n",
    "        configurator = self.processor_configurator()\n",
    "        loop=True\n",
    "        while loop:\n",
    "            processed_img = self._processor(image=image)\n",
    "            raw_value = [\n",
    "                value for _, value, _ in self._reader.readtext(processed_img)\n",
    "            ]\n",
    "            \n",
    "            result = self._pattern_check(raw_value, **rules)\n",
    "            if result is not None:\n",
    "                return result\n",
    "            else:\n",
    "                try:\n",
    "                    loop = configurator.__next__()\n",
    "                except StopIteration:\n",
    "                    return None\n",
    "                \n",
    "\n",
    "    def _value_check(self, raw_value: list):\n",
    "        parts = len(raw_value)\n",
    "        if parts == 1:\n",
    "            try:\n",
    "                check_result = float(raw_value[0])\n",
    "                if check_result > 1000:\n",
    "                    raw_result = str(check_result)\n",
    "                    raw_result = raw_result[:3] + '.' + raw_result[4]\n",
    "            except:\n",
    "                raw_result = None\n",
    "\n",
    "        elif parts == 2:\n",
    "            raw_result = '.'.join(raw_value)\n",
    "\n",
    "        elif parts == 3:\n",
    "            raw_result = f'{raw_value[0]}.{raw_value[2]}'\n",
    "\n",
    "        try:\n",
    "            result = float(raw_result)\n",
    "        except:\n",
    "            result = None\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a\u001b[39m.\u001b[39;49m\u001b[39m__next__\u001b[39;49m()\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recognize\n",
    "print('Starting recognizer...')\n",
    "reader = easyocr.Reader(['en'])\n",
    "checker = ValueChecker(reader=reader, processor=image_processor)\n",
    "\n",
    "input_fps = input('Input number of frames per second: ')\n",
    "try:\n",
    "    read_fps = float(input_fps)\n",
    "except:\n",
    "    read_fps = 1\n",
    "\n",
    "print('Recognizing:')\n",
    "errors = 0\n",
    "frame_line = tqdm(iterable=range(0, FPS * LENTH, int(FPS / read_fps)))\n",
    "frame_line.set_description(f'Errors: {errors: >4}')\n",
    "data = []\n",
    "for i_frame in frame_line:\n",
    "    CAP.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
    "    _, frame = CAP.read()\n",
    "    i_text = {'time': round(i_frame / FPS, 1)}\n",
    "    for variable in RECOGNIZABLE_VARIABLES:\n",
    "        selection = strict(frame, *variable['slice'])\n",
    "        processed_img = image_processor(selection)\n",
    "        raw_value = [value for _, value, _ in reader.readtext(processed_img)]\n",
    "        \n",
    "        mark, result = checker.check(image=selection,\n",
    "                               raw_value=raw_value,\n",
    "                               rules=variable['rules'])\n",
    "        i_text[variable['name']] = result\n",
    "        i_text[variable['name']+'_mark'] = mark\n",
    "\n",
    "    if None in i_text.values():\n",
    "        errors += 1\n",
    "        frame_line.set_description(f'Errors: {errors: >4}')\n",
    "    data.append(i_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print\n",
    "print(pd.DataFrame(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('zVid_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5946b119aa0342abd5386a0c5beb8d13f5e9da65c541c34995194e58e5a123e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
