{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import copy\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.widgets import Slider\n",
        "\n",
        "self()\n",
        "\n",
        "class Splitter:\n",
        "    parametr_configurations = []\n",
        "    parametrs = {}\n",
        "\n",
        "    def _build_selection_window(\n",
        "        self,\n",
        "        video_capture,\n",
        "        window_name: str = 'Selection window',\n",
        "        start_frame: int = 0,\n",
        "    ):\n",
        "        cv2.namedWindow(window_name)\n",
        "        # Our ROI, defined by two points\n",
        "        point0, point1 = (0, 0), (0, 0)\n",
        "        drawing = False  # True while ROI is actively being drawn by mouse\n",
        "        show_drawing = False  # True while ROI is drawn but is pending use or cancel\n",
        "        blue_color = (255, 0, 0)\n",
        "\n",
        "        def on_mouse(event, x, y, flags, userdata):\n",
        "            nonlocal point0, point1, drawing, show_drawing\n",
        "            if event == cv2.EVENT_LBUTTONDOWN:\n",
        "                # Left click down (select first point)\n",
        "                drawing = True\n",
        "                show_drawing = True\n",
        "                point0 = x, y\n",
        "                point1 = x, y\n",
        "            elif event == cv2.EVENT_MOUSEMOVE:\n",
        "                # Drag to second point\n",
        "                if drawing:\n",
        "                    point1 = x, y\n",
        "            elif event == cv2.EVENT_LBUTTONUP:\n",
        "                # Left click up (select second point)\n",
        "                drawing = False\n",
        "                point1 = x, y\n",
        "\n",
        "        cv2.setMouseCallback(window_name, on_mouse)\n",
        "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "        fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "        i_frame = start_frame\n",
        "        while True:\n",
        "            i_frame += 1\n",
        "            capture_ready, frame = video_capture.read()\n",
        "            # Reset timer when video ends\n",
        "            if not capture_ready:\n",
        "                i_frame = start_frame\n",
        "                video_capture.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
        "                capture_ready, frame = video_capture.read()\n",
        "\n",
        "            frame = self.process(frame, gray_image=False)\n",
        "\n",
        "            # Show rectangle\n",
        "            if show_drawing:\n",
        "                point1 = (0 if point1[0] < 0 else\n",
        "                          (point1[0]\n",
        "                           if point1[0] < frame.shape[1] else frame.shape[1]),\n",
        "                          0 if point1[1] < 0 else\n",
        "                          (point1[1]\n",
        "                           if point1[1] < frame.shape[0] else frame.shape[0]))\n",
        "\n",
        "                cv2.rectangle(frame, point0, point1, blue_color, 2)\n",
        "            cv2.imshow(window_name, frame)\n",
        "\n",
        "            keyboard = cv2.waitKey(1)\n",
        "            # Pressed Enter or Space to cunsume\n",
        "            if keyboard in [13, 32]:\n",
        "                drawing = False\n",
        "                cv2.destroyAllWindows()\n",
        "                break\n",
        "\n",
        "            # Pressed C or Esc to cancel selection\n",
        "            elif keyboard in [ord('c'), ord('C'), 27]:\n",
        "                point0 = (0, 0)\n",
        "                point1 = (0, 0)\n",
        "\n",
        "            # Pressed r to reset video timer\n",
        "            elif keyboard in [ord('r'), ord('R')]:\n",
        "                i_frame = start_frame\n",
        "                video_capture.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
        "\n",
        "            elif keyboard in [ord('q')]:\n",
        "                i_frame -= fps * 30\n",
        "                video_capture.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
        "\n",
        "            elif keyboard in [ord('e')]:\n",
        "                i_frame += fps * 30\n",
        "                video_capture.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
        "\n",
        "        cv2.destroyAllWindows()\n",
        "        return point0, point1\n",
        "\n",
        "    def select_window(self, video_capture, start_frame: int = 0):\n",
        "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "        _, image = video_capture.read()\n",
        "        for window in self.windows:\n",
        "            point0,point1 = self._build_selection_window(\n",
        "                video_capture,window_name=f\"Select {window}\",\n",
        "                start_frame=start_frame,\n",
        "                )\n",
        "            if (point0, point1) == ((0, 0), (0, 0)):\n",
        "                point1 = image.shape[:2:][::-1]\n",
        "            self.windows[window] = (point0, point1)\n",
        "\n",
        "    def strict(self, image: np.ndarray) -> np.ndarray:\n",
        "        images = {}\n",
        "        for variable, window in self.windows.items():\n",
        "            (x0, y0), (x1, y1) = window\n",
        "            X, Y = (x0, x1), (y0, y1)\n",
        "            x0, x1 = min(X), max(X)\n",
        "            y0, y1 = min(Y), max(Y)\n",
        "\n",
        "            images[variable] = image[y0:y1, x0:x1]\n",
        "        return images\n",
        "\n",
        "    def __call__(self, image: np.ndarray, gray_image=True) -> np.ndarray:\n",
        "        if gray_image:\n",
        "            try:\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            except:\n",
        "                pass\n",
        "            image = cv2.bitwise_not(image)\n",
        "        return image\n",
        "\n",
        "    def __init__(self, variable_names):\n",
        "        self.windows = {variable: (0, 0) for variable in variable_names}\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.parametrs[item]\n",
        "\n",
        "    def __setitem__(self, item, value):\n",
        "        self.parametrs[item] = value\n",
        "\n",
        "    def check_process(\n",
        "        self,\n",
        "        video_capture,\n",
        "        start_frame: int = 0,\n",
        "        end_frame: int = 0,\n",
        "    ):\n",
        "\n",
        "        def update(val):\n",
        "            time = TIME_slider.val\n",
        "            video_capture.set(cv2.CAP_PROP_POS_FRAMES, int(fps * time))\n",
        "            _, image = video_capture.read()\n",
        "\n",
        "            image_processed = self.process(image)\n",
        "            stricted_images_list = self.strict(image_processed)\n",
        "\n",
        "            i = 0\n",
        "            for variable in self.windows:\n",
        "                plots[i].set_data(stricted_images_list[variable])\n",
        "                plots[i].autoscale()\n",
        "                i += 1\n",
        "\n",
        "            fig.canvas.draw_idle()\n",
        "\n",
        "        fig, axises = plt.subplots(nrows=len(self.windows) + 1)\n",
        "        fig.set_size_inches(5, 5)\n",
        "        fig.subplots_adjust(\n",
        "            left=0.1,\n",
        "            right=0.9,\n",
        "            bottom=0.0,\n",
        "            top=1,\n",
        "            hspace=0.0,\n",
        "            wspace=0.1,\n",
        "        )\n",
        "        if not isinstance(axises, np.ndarray): axises = [axises]\n",
        "\n",
        "        time_slider_ax = axises[0]\n",
        "        axises = axises[1:]\n",
        "\n",
        "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "        _, image = video_capture.read()\n",
        "        image_processed = self.process(image)\n",
        "        stricted_images_list = self.strict(image_processed)\n",
        "\n",
        "        plots = []\n",
        "        i = 0\n",
        "        for variable in self.windows:\n",
        "            plots.append(\n",
        "                axises[i].imshow(\n",
        "                    stricted_images_list[variable],\n",
        "                    cmap='binary',\n",
        "                ), )\n",
        "            i += 1\n",
        "        fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "        max_len = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT) / fps) - 1\n",
        "        end_frame = max_len if not end_frame else end_frame\n",
        "\n",
        "        TIME_slider = Slider(\n",
        "            ax=time_slider_ax,\n",
        "            label='Time',\n",
        "            valmin=start_frame,\n",
        "            valmax=end_frame,\n",
        "            valinit=start_frame,\n",
        "            valstep=1,\n",
        "        )\n",
        "        TIME_slider.on_changed(update)\n",
        "        plt.show()\n",
        "\n",
        "    # def configure_process(\n",
        "    #     self,\n",
        "    #     video_capture,\n",
        "    #     start_frame: int = 0,\n",
        "    #     end_frame: int = 0,\n",
        "    # ):\n",
        "\n",
        "    #     def update(val):\n",
        "    #         time = TIME_slider.val\n",
        "    #         video_capture.set(cv2.CAP_PROP_POS_FRAMES, int(fps * time))\n",
        "    #         _, image = video_capture.read()\n",
        "\n",
        "    #         for slider in sliders:\n",
        "    #             slider_name = str(slider.label).split(\"'\")[1]\n",
        "    #             self[slider_name] = slider.val\n",
        "\n",
        "    #         image_processed = self.process(image)\n",
        "    #         plot.set_data(image_processed)\n",
        "    #         plot.autoscale()\n",
        "    #         fig.canvas.draw_idle()\n",
        "\n",
        "    #     fig, ax = plt.subplots()\n",
        "    #     fig.set_size_inches(5, 5)\n",
        "    #     fig.subplots_adjust(\n",
        "    #         left=0.25,\n",
        "    #         right=1,\n",
        "    #         bottom=0.25,\n",
        "    #         top=1,\n",
        "    #         hspace=0,\n",
        "    #         wspace=0,\n",
        "    #     )\n",
        "    #     video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "    #     _, image = video_capture.read()\n",
        "\n",
        "    #     plot = ax.imshow(self.process(image), cmap='binary')\n",
        "\n",
        "    #     time_slider_ax = fig.add_axes([0.25, 0.1, 0.65, 0.03])\n",
        "    #     fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "    #     max_len = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT) / fps) - 1\n",
        "    #     end_frame = max_len if not end_frame else end_frame\n",
        "\n",
        "    #     TIME_slider = Slider(\n",
        "    #         ax=time_slider_ax,\n",
        "    #         label='Time',\n",
        "    #         valmin=start_frame,\n",
        "    #         valmax=end_frame,\n",
        "    #         valinit=start_frame,\n",
        "    #         valstep=1,\n",
        "    #     )\n",
        "    #     TIME_slider.on_changed(update)\n",
        "\n",
        "    #     sliders = []\n",
        "    #     ofset = 0.2\n",
        "    #     for parametr, diap in self.parametr_configurations.items():\n",
        "    #         slider_ax = fig.add_axes([ofset, 0.25, 0.03, 0.6])\n",
        "\n",
        "    #         p_min = min(diap)\n",
        "    #         p_max = max(diap)\n",
        "    #         p_step = (max(diap) - min(diap)) / (len(diap) - 1)\n",
        "\n",
        "    #         slider = Slider(\n",
        "    #             ax=slider_ax,\n",
        "    #             orientation='vertical',\n",
        "    #             label=parametr,\n",
        "    #             valmin=p_min,\n",
        "    #             valmax=p_max,\n",
        "    #             valinit=self[parametr],\n",
        "    #             valstep=p_step,\n",
        "    #         )\n",
        "    #         slider.on_changed(update)\n",
        "    #         sliders.append(slider)\n",
        "    #         ofset -= 0.02\n",
        "\n",
        "    #     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class PostProcessor:\n",
        "    pattern = ''\n",
        "    inside_info = {}\n",
        "    input_value = []\n",
        "    image = []\n",
        "\n",
        "    def check(self, input_value, pattern, image, inside_info={}):\n",
        "        self.pattern = pattern\n",
        "        pattern_check = self.isOK(input_value)\n",
        "        if pattern_check is not None: return 'OK', pattern_check\n",
        "        self.image = image\n",
        "        self.inside_parametrs = inside_info\n",
        "        for check_name, check_func in self.active_checks_order.items():\n",
        "            check_result = check_func(self)\n",
        "            if check_result is not None: return check_name, check_result\n",
        "        return 'error', None\n",
        "\n",
        "    def convert(self, value: str):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @staticmethod\n",
        "    def check_type(func=None, get=False, checks={}):\n",
        "        if func is not None: checks.update({func.__name__: func})\n",
        "        if get: return checks\n",
        "        return func\n",
        "\n",
        "    def isOK(self, raw_value: list):\n",
        "        if raw_value == []: return None\n",
        "        value = raw_value[0]\n",
        "        if re.match(self.pattern, value):\n",
        "            return self.convert(value)\n",
        "\n",
        "    @check_type\n",
        "    def OK_inner(self):\n",
        "        processed_image = self.inner_processor(self.image)\n",
        "        raw_value = [value for _, value, _ in self.reader.readtext(processed_image)]\n",
        "        return self.isOK(raw_value)\n",
        "\n",
        "    def __init__(self, processor: Splitter, reader: cv2.VideoCapture):\n",
        "        self.inner_processor: Splitter = copy.deepcopy(processor)\n",
        "        self.reader: cv2.VideoCapture = reader\n",
        "        self.active_checks_order = self.check_type(get=True)\n",
        "\n",
        "    @property\n",
        "    def all_checks(self):\n",
        "        return self.check_type(get=True)\n",
        "\n",
        "    def reload_processor(self, processor):\n",
        "        self.inner_processor = copy.deepcopy(processor)\n",
        "\n",
        "\n",
        "def get_paths(video_path='', data_path='', data_format='csv'):\n",
        "\n",
        "    if video_path == '':\n",
        "        while (video_path == '') or (not os.path.isfile(video_path)):\n",
        "            video_path = input(f\"Input video path: \")\n",
        "\n",
        "    path_list = (video_path).split('\\\\')\n",
        "    folder_path = '\\\\'.join(path_list[:-1])\n",
        "    video_name = path_list[-1]\n",
        "    video_path = video_path.replace('\\\\', '\\\\')\n",
        "\n",
        "    if data_path == '':\n",
        "        data_name = video_name.split('.')[0]\n",
        "        while os.path.isfile(f'{folder_path}\\\\{data_name}.{data_format}'):\n",
        "            data_name = input(f\"Data exists, input new name: \")\n",
        "        data_path = f'{folder_path}\\\\{data_name}.{data_format}'\n",
        "\n",
        "    return {'data': data_path, 'video': video_path}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib qt\n",
        "# %matplotlib ipympl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Imports\n",
        "print(\"Importing...\")\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "import easyocr\n",
        "\n",
        "# from recognizer_modules import PreProcessor, PostProcessor, PathContainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Inputs\n",
        "PATHS = get_paths(video_path='', data_path='', data_format='csv')\n",
        "\n",
        "VARIABLE_PATTERNS = {\n",
        "    'Viscosity': r'-?\\d{1,3}[\\.,]\\d',\n",
        "    'Temperature': r'-?\\d{1,3}[\\.,]\\d',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configurate image processing\n",
            "Press:\n",
            "   Enter - save selection and continue\n",
            "   R     - reset video timer\n",
            "   Ecs/C - cancel selection\n",
            "   q/e   - time move\n"
          ]
        }
      ],
      "source": [
        "## PreProcessor settings\n",
        "class ImageProcessor(Splitter):...\n",
        "    # Blur = range(1, 50)\n",
        "\n",
        "    # def HHHH(self, image, gray_image=True):\n",
        "    #     image = cv2.blur(image, (int(self['Blur']), int(self['Blur'])))\n",
        "\n",
        "\n",
        "\n",
        "CAP = cv2.VideoCapture(PATHS['video'])\n",
        "\n",
        "FPS = int(CAP.get(cv2.CAP_PROP_FPS))\n",
        "LENTH = int(CAP.get(cv2.CAP_PROP_FRAME_COUNT) / FPS)\n",
        "CAP.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "_, START_FRAME = CAP.read()\n",
        "\n",
        "processor = ImageProcessor([i for i in VARIABLE_PATTERNS])\n",
        "print('Configurate image processing')\n",
        "# processor.configure_process(CAP)\n",
        "print(\n",
        "    'Press:',\n",
        "    '   Enter - save selection and continue',\n",
        "    '   R     - reset video timer',\n",
        "    '   Ecs/C - cancel selection',\n",
        "    '   q/e   - time move',\n",
        "    sep='\\n',\n",
        ")\n",
        "processor.select_window(CAP)\n",
        "processor.check_process(CAP)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## PostProcessor settings\n",
        "class ValuePostProcessor(PostProcessor):\n",
        "\n",
        "    def convert(self, value: str):\n",
        "        value = value.replace(',', '.')\n",
        "        try:\n",
        "            result = float(value)\n",
        "            return result\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    @PostProcessor.check_type\n",
        "    def image_sweep_check(self) -> list[str]:\n",
        "        for i in range(1, 50):\n",
        "            self.inner_processor['Blur'] = i\n",
        "            processed_img = self.inner_processor(self.image)\n",
        "            raw_value = [\n",
        "                value for _, value, _ in self.reader.readtext(processed_img)\n",
        "            ]\n",
        "            result = self.isOK(raw_value)\n",
        "            if result is not None: return result\n",
        "\n",
        "    @PostProcessor.check_type\n",
        "    def combine_check(self) -> list[str]:\n",
        "        parts = len(self.input_value)\n",
        "        if parts == 1:\n",
        "            value = self.input_value[0]\n",
        "            combined_value = value[:3] + '.' + value[4:5]\n",
        "\n",
        "        elif parts == 2:\n",
        "            combined_value = '.'.join(self.input_value)\n",
        "\n",
        "        elif parts == 3:\n",
        "            combined_value = f'{self.input_value[0]}.{self.input_value[2]}'\n",
        "\n",
        "        return self.isOK(combined_value)\n",
        "\n",
        "\n",
        "print('Starting recognizer...')\n",
        "reader = easyocr.Reader(['en'])\n",
        "checker = ValuePostProcessor(reader=reader, processor=processor)\n",
        "# checker.active_checks_order =\n",
        "# {check:checker.all_checks[check]\n",
        "# for check in ['inner_processor_check','value_combine']}\n",
        "print('Active checks:\\n', [i for i in checker.active_checks_order])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Recognize\n",
        "input_fps = input('Input number of frames per second: ')\n",
        "try:\n",
        "    read_fps = float(input_fps)\n",
        "except:\n",
        "    read_fps = 1\n",
        "\n",
        "print('Recognizing:')\n",
        "errors = 0\n",
        "frame_line = tqdm(iterable=range(0, FPS * LENTH, int(FPS / read_fps)))\n",
        "frame_line.set_description(f'Errors: {errors: >4}')\n",
        "DATA = []\n",
        "\n",
        "for i_frame in frame_line:\n",
        "    CAP.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
        "    _, frame = CAP.read()\n",
        "    i_text = {'time': round(i_frame / FPS, 1)}\n",
        "    processed_frame = processor(frame)\n",
        "    stricted_images = processor.strict(processed_frame)\n",
        "\n",
        "    for var, pattern in VARIABLE_PATTERNS.items():\n",
        "        var_image = stricted_images[var]\n",
        "        raw_value = [value for _, value, _ in reader.readtext(var_image)]\n",
        "\n",
        "        verbose, result = checker.check(\n",
        "            input_value=raw_value,\n",
        "            pattern=pattern,\n",
        "            image = var_image,\n",
        "            )\n",
        "\n",
        "        # if mark == 'error':\n",
        "        #     # processor.configure_process(CAP,start_frame=i_frame)\n",
        "        #     processor.select_window(CAP,start_frame=i_frame)\n",
        "        #     # processor.check_process(CAP,start_frame=i_frame)\n",
        "        #     checker.reload_processor(processor)\n",
        "        #     mark, result = checker.check(image=var_image,\n",
        "        #                 raw_value=raw_value,\n",
        "        #                 rules=rules)\n",
        "        #     mark= f'*{mark}'\n",
        "\n",
        "        i_text[var] = result\n",
        "        i_text[var + '_verbose'] = verbose\n",
        "\n",
        "    if None in i_text.values():\n",
        "        errors += 1\n",
        "        frame_line.set_description(f'Errors: {errors: >4}')\n",
        "    DATA.append(i_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Saving\n",
        "df = pd.DataFrame(DATA)\n",
        "df.to_csv(PATHS['data'])"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.10.0 ('zChemistry_env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "65e3ff7ea178c0cc827c55669acecc2d3bcf4faf0bb1a0873412f31fa3e54b71"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
